# handlers/training_handlers.py
import io
import base64
import json
import asyncio
from collections import deque
import httpx # NEW: for downloading media in training mode

import config
from utils.utils import save_for_training_conversation_log, notify_human_on_whatsapp, translate_qa_pair_with_gpt
from services.photo_analysis_service import get_bot_photo_analysis_from_gpt
from services.training_response_service import process_training_request_with_gpt
from services.llm_core_service import client as openai_client
# Try to import pydub, handle gracefully if it fails
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError as e:
    print(f"Warning: pydub not available in training_handlers - {e}")
    PYDUB_AVAILABLE = False
    AudioSegment = None

# User-specific training state (moved from global 'training_stage')
# Using config.training_stage = defaultdict(int) defined in config.py
# Using config.last_generated_qa_for_save = defaultdict(list) defined in config.py


async def start_training_mode(user_id: str, user_data: dict, send_message_func, send_action_func):
    """
    Activates the smart training mode for the trainer on WhatsApp.
    """
    if user_id == config.TRAINER_WHATSAPP_NUMBER: # Use WhatsApp number for trainer ID check
        config.user_in_training_mode[user_id] = True
        config.training_stage[user_id] = 1 # Enters free interaction mode
        config.last_generated_qa_for_save[user_id].clear() # Clear any previous data

        # Ensure training conversation context is initialized/cleared
        if 'training_conversation_context' not in user_data:
            user_data['training_conversation_context'] = deque(maxlen=config.MAX_CONTEXT_MESSAGES_TRAINING)
        user_data['training_conversation_context'].clear() # Clear previous training context

        trainer_preferred_lang = user_data.get('user_preferred_lang', 'ar')

        initial_message_map = {
            "ar": "ØªÙ… ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ. ğŸ¤–\nØ§Ù„Ø¢Ù†ØŒ Ø£Ø±Ø³Ù„ Ù„ÙŠ **ØªØ¹Ù„ÙŠÙ…Ø§ØªÙƒ Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù€ GPT** (Ù†Øµ Ø£Ùˆ ØµÙˆØª Ø£Ùˆ ØµÙˆØ±Ø©).\nÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªØ·Ù„Ø¨:\n1.  **'Ø³Ø¤Ø§Ù„ ÙˆØ¬ÙˆØ§Ø¨ Ø¹Ù† ÙƒØ°Ø§'**: Ù„Ø£ØªÙˆÙ„Ù‘Ø¯ Ù„Ùƒ Ø£Ø²ÙˆØ§Ø¬ Q&A Ø¨Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹ (Ø¹Ø±Ø¨ÙŠØŒ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØŒ ÙØ±Ù†Ø³ÙŠØŒ ÙØ±Ù†ÙƒÙˆ) Ù„Ù„Ø­ÙØ¸.\n2.  **'Ù„Ø®Øµ' / 'Ø´Ùˆ Ø§ØªÙÙ‚Ù†Ø§'**: Ù„Ø£Ù„Ø®Ù‘Øµ Ù„Ùƒ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙƒÙ€ Q&A Ù„Ù„Ø­ÙØ¸.\n3.  **'Ø¹Ø¯Ù‘Ù„ Ù‡Ø°Ø§' / 'ÙƒÙˆÙ† ÙˆØ¯ÙˆØ¯ Ø£ÙƒØ«Ø±' / 'Ø­Ø· Ø¥ÙŠÙ…ÙˆØ¬ÙŠ'**: Ù„Ø£Ø¹Ø¯Ù‘Ù„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ø±Ø¯ Ù„Ù€ GPT. (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†ØµÙŠØ§Ù‹ Ø¹Ø§Ø¯ÙŠØ§Ù‹).\n4.  **ØµÙˆØ±Ø©**: Ù„Ø£Ø­Ù„Ù„Ù‡Ø§ ÙˆØªØ·Ù„Ø¨ Ù…Ù†ÙŠ ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„/Ø¬ÙˆØ§Ø¨ Ø­ÙˆÙ„Ù‡Ø§.\nÙ„Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹ØŒ Ø§ÙƒØªØ¨ /exit\nÙ„Ù„Ø­ÙØ¸ (Ø¨Ø¹Ø¯ ØªÙˆÙ„ÙŠØ¯ Q&A Ø£Ùˆ ØªÙ„Ø®ÙŠØµÙ‡Ø§): Ø£Ø±Ø³Ù„ 'Ø§Ø­ÙØ¸' Ø£Ùˆ '/save'.",
            "en": "Smart training mode activated. ğŸ¤–\nNow, send me your **instructions directly to GPT** (text, voice, or image).\nYou can ask:\n1.  **'Question and answer about X'**: To generate Q&A pairs in 4 languages (AR, EN, FR, Franco) for saving.\n2.  **'Summarize' / 'What did we agree on'**: To summarize the conversation as Q&A for saving.\n3.  **'Edit this' / 'Be more friendly' / 'Add emoji'**: To modify GPT's last response (if it was plain text).\n4.  **Image**: To analyze it and ask me to formulate a Q&A about it.\nTo exit, type /exit\nTo save (after Q&A generation or summarization): send 'save' or '/save'.",
            "fr": "Mode d'entraÃ®nement intelligent activÃ©. ğŸ¤–\nMaintenant, envoyez-moi vos **instructions directement Ã  GPT** (texte, voix ou image).\nVous pouvez demander :\n1.  **'Question et rÃ©ponse sur X'**: Pour gÃ©nÃ©rer des paires Q&A en 4 langues (AR, EN, FR, Franco) Ã  enregistrer.\n2.  **'RÃ©sumer' / 'Qu'avons-nous convenu'**: Pour rÃ©sumer la conversation en Q&A Ã  enregistrer.\n3.  **'Modifier ceci' / 'Sois plus amical' / 'Ajoute des emojis'**: Pour modifier la derniÃ¨re rÃ©ponse de GPT (si c'Ã©tait du texte brut).\n4.  **Image**: Pour l'analyser et me demander de formuler une Q&A Ã  ce sujet.\nPour quitter, tapez /exit\nPour enregistrer (aprÃ¨s gÃ©nÃ©ration Q&A ou rÃ©sumÃ© Q&A) : envoyez 'enregistrer' ou '/save'.",
            "franco": "Hello! ğŸ˜Š\nMa3ak Linaâ€™s Laser â€“ El mosa3ed el zaki bel zaka2 el istina3e.\nKifak? Kif fini sa3edak el yom? ğŸ§ âœ¨\n\nFik t7kili bi ay tari2a bte7ebbaha â€“ 7atta law bel sawt! ğŸ¤\nAna hon mchan sa3edak bi ay chi baddak yeh, bi kel souhoule w ser3a.\nJahiz? Yalla ne7ki! ğŸ¤–ğŸ’¬\n\nW bel monasabe, kermel ne2dar nsa3edak w ne2addemlak afdal khedme, mumkin tkabbirna law sama7t iza inta chab aw inti sabieh? ğŸ‘¦ğŸ‘§"
        }
        await send_message_func(user_id, initial_message_map.get(trainer_preferred_lang, initial_message_map['ar']))
    else:
        await send_message_func(user_id, "Ù„ÙŠØ³ Ù„Ø¯ÙŠÙƒ ØµÙ„Ø§Ø­ÙŠØ© Ù„ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.")

async def exit_training_mode(user_id: str, user_data: dict, send_message_func, send_action_func):
    """
    Deactivates the smart training mode for the trainer on WhatsApp.
    """
    if user_id == config.TRAINER_WHATSAPP_NUMBER:
        config.user_in_training_mode[user_id] = False
        config.training_stage[user_id] = 0 # Reset state
        config.last_generated_qa_for_save[user_id].clear() # Clear any previous data
        if 'training_conversation_context' in user_data:
            user_data['training_conversation_context'].clear() # Clear training context as well
        await send_message_func(user_id, "ØªÙ… Ø¥Ù„ØºØ§Ø¡ ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ø¹Ø§Ø¯ Ø§Ù„Ø¨ÙˆØª Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ.")
    else:
        await send_message_func(user_id, "Ù„ÙŠØ³ Ù„Ø¯ÙŠÙƒ ØµÙ„Ø§Ø­ÙŠØ© Ù„Ø¥Ù„ØºØ§Ø¡ ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.")

async def save_generated_data_to_log(user_id: str, send_message_func):
    """
    Saves the last generated Q&A data to the conversation log.
    """
    if user_id != config.TRAINER_WHATSAPP_NUMBER:
        await send_message_func(user_id, "Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ù…Ø®ØµØµ Ù„Ù„Ù…Ø¯Ø±Ø¨ÙŠÙ† ÙÙ‚Ø·.")
        return

    data_to_save = config.last_generated_qa_for_save.get(user_id)
    if not data_to_save:
        await send_message_func(user_id, "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ù…ÙˆÙ„Ø¯Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ Ù„Ø­ÙØ¸Ù‡Ø§. ÙŠØ±Ø¬Ù‰ ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ø£ÙˆÙ„Ø§Ù‹ (Ø¹Ø¨Ø± Ø·Ù„Ø¨ 'Ø³Ø¤Ø§Ù„ ÙˆØ¬ÙˆØ§Ø¨ Ø¹Ù† ÙƒØ°Ø§' Ø£Ùˆ 'Ù„Ø®Øµ').")
        return

    try:
        if not isinstance(data_to_save, list):
            await send_message_func(user_id, "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù„ÙŠØ³Øª Ø¨ØµÙŠØºØ© ØµØ­ÙŠØ­Ø© Ù„Ù„Ø­ÙØ¸ (Ù„ÙŠØ³Øª Ù‚Ø§Ø¦Ù…Ø©).")
            print(f"ERROR: Data to save is not a list: {data_to_save}")
            return

        for entry in data_to_save:
            if isinstance(entry, dict) and 'question' in entry and 'answer' in entry and 'language' in entry:
                save_for_training_conversation_log(entry["question"], entry["answer"])
            else:
                await send_message_func(user_id, f"ØªØ­Ø°ÙŠØ±: Ø¹Ù†ØµØ± ØºÙŠØ± ØµØ§Ù„Ø­ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©ØŒ Ù„Ù† ÙŠØªÙ… Ø­ÙØ¸Ù‡: {entry}")
                print(f"Invalid generated data entry: {entry}")

        config.load_training_data() # Load training data immediately after saving to update bot's knowledge in real-time

        await send_message_func(user_id, "ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ø¨Ù†Ø¬Ø§Ø­ ÙˆØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙˆØª! âœ…")
        config.last_generated_qa_for_save[user_id].clear()
        config.training_stage[user_id] = 1 # Trainer can send new instructions directly
    except Exception as e:
        await send_message_func(user_id, f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
        notify_human_on_whatsapp(config.user_names.get(user_id, "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"), config.user_gender.get(user_id, "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"),
                                 f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø±Ø¨ {config.user_names.get(user_id)}: {e}",
                                 type_of_notification="Ø®Ø·Ø£ ØªØ¯Ø±ÙŠØ¨")

async def handle_training_input(user_id: str, user_name: str = "Ù…Ø¯Ø±Ø¨", user_input_text: str = None, audio_data_bytes: io.BytesIO = None, image_url: str = None, user_data: dict = None, send_message_func = None, send_action_func = None):
    """
    Handles input from the trainer in training mode, supporting text, voice, and photo.
    """
    if user_id != config.TRAINER_WHATSAPP_NUMBER or not config.user_in_training_mode.get(user_id, False):
        await send_message_func(user_id, "Ø£Ù†Øª Ù„Ø³Øª ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø¯ÙŠØ± Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ØºØ¨ Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨.")
        return

    # Check for /exit command
    if user_input_text and user_input_text.lower() == "/exit":
        await exit_training_mode(user_id, user_data, send_message_func, send_action_func)
        return

    # Handle /save command
    if user_input_text and any(kw in user_input_text.lower() for kw in config.SAVE_KEYWORDS):
        await save_generated_data_to_log(user_id, send_message_func)
        return

    processed_input_for_gpt = None # This will be the textual instruction sent to GPT
    
    # Ensure user_data['training_conversation_context'] exists
    if 'training_conversation_context' not in user_data:
        user_data['training_conversation_context'] = deque(maxlen=config.MAX_CONTEXT_MESSAGES_TRAINING)

    # Process input based on type
    if audio_data_bytes:
        if not PYDUB_AVAILABLE:
            await send_message_func(user_id, "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ØµÙˆØªÙŠØ© ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ ØªØ¹Ù„ÙŠÙ…Ø§ØªÙƒ Ù†ØµÙŠØ§Ù‹.")
            return
            
        await send_message_func(user_id, "Ø¬Ø§Ø±Ù ØªØ­ÙˆÙŠÙ„ Ø±Ø³Ø§Ù„ØªÙƒ Ø§Ù„ØµÙˆØªÙŠØ© Ø¥Ù„Ù‰ Ù†Øµ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨... ğŸ§")
        await send_action_func(user_id)
        try:
            audio = AudioSegment.from_file(audio_data_bytes, format="ogg") # Assuming OGG for WhatsApp voice notes
            mp3_buffer = io.BytesIO()
            audio.export(mp3_buffer, format="mp3")
            mp3_buffer.seek(0)
            mp3_buffer.name = "voice_training_instruction.mp3"

            transcription_response = await openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=mp3_buffer,
                language="ar" # Arabic for transcription
            )
            processed_input_for_gpt = transcription_response.text
            await send_message_func(user_id, f"ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ: \"{processed_input_for_gpt}\"\n")

        except Exception as e:
            print(f"âŒ ERROR processing voice message for training instruction: {e}")
            await send_message_func(user_id, "ğŸš« Ø¢Ø³ÙØ©ØŒ Ù„Ù… Ø£Ø³ØªØ·Ø¹ ÙÙ‡Ù… Ø±Ø³Ø§Ù„ØªÙƒ Ø§Ù„ØµÙˆØªÙŠØ© Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø£Ùˆ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ù†ØµÙŠØ§Ù‹.")
            return

    elif image_url:
        await send_message_func(user_id, "ØªÙ„Ù‚ÙŠØª ØµÙˆØ±Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨. Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© GPT... ğŸ“¸")
        await send_action_func(user_id)
        if config.user_photo_analysis_count[user_id] >= config.MAX_PHOTO_ANALYSIS_PER_USER:
             await send_message_func(user_id, "ÙˆØµÙ„Øª Ù„Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚ØµÙˆÙ‰ Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£ÙŠØ¶Ø§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø·ÙˆØ±.")
             return
        try:
            async with httpx.AsyncClient() as client:
                photo_response = await client.get(image_url)
                photo_response.raise_for_status()
                photo_data_bytes = io.BytesIO(photo_response.content)
                photo_data_bytes.seek(0)
            base64_image = base64.b64encode(photo_data_bytes.read()).decode("utf-8")

            bot_initial_reply, analysis_data = await get_bot_photo_analysis_from_gpt(user_id, base64_image, is_training_quiz=True)

            processed_input_for_gpt = (
                f"Ù„Ø¯ÙŠ ØµÙˆØ±Ø© ØªÙ… ØªØ­Ù„ÙŠÙ„Ù‡Ø§. Ø§Ù„ÙˆØµÙ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù„Ù€ GPT Ù‡Ùˆ: {analysis_data.get('description', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}ØŒ "
                f"Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‚ØªØ±Ø­: {analysis_data.get('type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}ØŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {analysis_data.get('location_on_body', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}. "
                f"Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ù‚ØªØ±Ø­ ÙƒØ§Ù†: '{bot_initial_reply}'.\n"
                "Ø§Ù„Ø¢Ù†ØŒ Ø£Ø±ØºØ¨ ÙÙŠ ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„ ÙˆØ¬ÙˆØ§Ø¨ Ù…Ø«Ø§Ù„ÙŠÙŠÙ† Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¨ÙˆØª Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ù‚ØªØ±Ø­."
            )
            config.user_photo_analysis_count[user_id] += 1

        except Exception as e:
            print(f"âŒ ERROR processing photo for training: {e}")
            await send_message_func(user_id, f"ğŸš« Ø¢Ø³ÙØ©ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±ØªÙƒ Ù„Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
            return
    
    elif user_input_text:
        processed_input_for_gpt = user_input_text
    
    if not processed_input_for_gpt: # No usable text after processing
        await send_message_func(user_id, "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù†ØµÙŠØ©ØŒ Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©ØŒ Ø£Ùˆ ØµÙˆØ±Ø©.")
        return

    # Now pass the trainer's instruction to GPT
    await send_action_func(user_id) # Show typing indicator
    
    # Determine if a JSON Q&A generation is explicitly requested by trainer keywords
    is_qa_generation_request = any(kw in processed_input_for_gpt.lower() for kw in config.GENERATE_QA_KEYWORDS)
    is_summary_qa_request = any(kw in processed_input_for_gpt.lower() for kw in config.SUMMARIZE_QA_KEYWORDS)

    gpt_response_obj = await process_training_request_with_gpt(
        user_id,
        processed_input_for_gpt,
        list(user_data['training_conversation_context']), # Pass conversation context
        is_qa_generation_request=is_qa_generation_request,
        is_summary_qa_request=is_summary_qa_request
    )

    # Save trainer's message and GPT's response to training conversation context
    user_data['training_conversation_context'].append({"role": "user", "content": processed_input_for_gpt})
    if gpt_response_obj and 'data' in gpt_response_obj:
        if isinstance(gpt_response_obj['data'], list): # If JSON Q&A
            user_data['training_conversation_context'].append({"role": "assistant", "content": json.dumps(gpt_response_obj['data'], ensure_ascii=False)})
        elif isinstance(gpt_response_obj['data'], str): # If plain text
            user_data['training_conversation_context'].append({"role": "assistant", "content": gpt_response_obj['data']})
        else:
            user_data['training_conversation_context'].append({"role": "assistant", "content": "Unrecognized GPT response format."})


    if gpt_response_obj and gpt_response_obj["type"] == "qa_list":
        config.last_generated_qa_for_save[user_id] = gpt_response_obj["data"]
        config.training_stage[user_id] = 2 # Generated, waiting for save command

        response_message = "ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªØ§Ù„ÙŠØ©:\n\n"
        for entry in gpt_response_obj["data"]:
            response_message += f"**Ø§Ù„Ù„ØºØ©:** `{entry.get('language', 'N/A').upper()}`\n"
            response_message += f"**Ø§Ù„Ø³Ø¤Ø§Ù„:** {entry.get('question', 'N/A')}\n"
            response_message += f"**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** {entry.get('answer', 'N/A')}\n\n"
        response_message += "Ø¥Ø°Ø§ ÙƒÙ†Øª Ø±Ø§Ø¶ÙŠØ§Ù‹ØŒ Ø£Ø±Ø³Ù„ Ù„ÙŠ Ø§Ù„Ø£Ù…Ø± **'Ø§Ø­ÙØ¸'** Ø£Ùˆ **'/save'** Ù„Ø­ÙØ¸ Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
        await send_message_func(user_id, response_message) # parse_mode='Markdown' might not be supported by WhatsApp text
    elif gpt_response_obj and gpt_response_obj["type"] == "text":
        config.last_generated_qa_for_save[user_id].clear() # Clear previous Q&A if it was a plain text response
        config.training_stage[user_id] = 1 # Remains in free interaction state
        
        await send_message_func(user_id, f"Ø±Ø¯ GPT:\n\n{gpt_response_obj['data']}")
        await send_message_func(user_id, "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø¥Ù…Ø§ Ø£Ù† ØªØ·Ù„Ø¨ ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø£Ùˆ ØªØ³Ø£Ù„ GPT Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø§Ù‹.\nØ¥Ø°Ø§ Ø£Ø±Ø¯Øª Ø­ÙØ¸ Ø¢Ø®Ø± Ø³Ø¤Ø§Ù„ ÙˆØ¬ÙˆØ§Ø¨ ØªÙ… Ø§Ù„ØªÙˆØµÙ„ Ø¥Ù„ÙŠÙ‡Ù…Ø§ ÙÙŠ Ø­ÙˆØ§Ø±Ù†Ø§ØŒ Ø£Ø±Ø³Ù„ **'Ù„Ø®Øµ'** Ø£Ùˆ **'Ø´Ùˆ Ø§ØªÙÙ‚Ù†Ø§'** (Ù„Ø·Ù„Ø¨ ØµÙŠØ§ØºØ© Q&A Ù„Ù„Ø­ÙØ¸).")
    else:
        await send_message_func(user_id, "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ ØµØ§Ù„Ø­ Ù…Ù† GPT. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
        config.last_generated_qa_for_save[user_id].clear()
        config.training_stage[user_id] = 1 # Remains in waiting for new instructions